"""
å¸å®‰BTCå†å²æ•°æ®çˆ¬å–è„šæœ¬
åŠŸèƒ½ï¼šè·å–å¤§é‡å†å²Kçº¿æ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒ
æ”¯æŒï¼šå¤šæ—¶é—´æ¡†æ¶ã€æ‰¹é‡è·å–ã€è‡ªåŠ¨ä¿å­˜
"""

import requests
import pandas as pd
import time
from datetime import datetime, timedelta
from pathlib import Path
import json


class BinanceHistoricalFetcher:
    """å¸å®‰å†å²æ•°æ®çˆ¬å–å™¨"""
    
    def __init__(self, symbol="BTCUSDT", interval="1h"):
        """
        åˆå§‹åŒ–
        :param symbol: äº¤æ˜“å¯¹ï¼Œå¦‚ BTCUSDT, ETHUSDT
        :param interval: Kçº¿é—´éš” (1m, 5m, 15m, 30m, 1h, 4h, 1d, 1w, 1M)
        """
        self.base_url = "https://api.binance.com/api/v3/klines"
        self.symbol = symbol
        self.interval = interval
        self.data_dir = Path(__file__).parent.parent / "data"
        
    def fetch_klines(self, start_time=None, end_time=None, limit=1000):
        """
        è·å–Kçº¿æ•°æ®ï¼ˆå•æ¬¡è¯·æ±‚ï¼‰
        :param start_time: å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰
        :param end_time: ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰
        :param limit: æ•°é‡é™åˆ¶ï¼ˆæœ€å¤§1000ï¼‰
        :return: DataFrame
        """
        params = {
            "symbol": self.symbol,
            "interval": self.interval,
            "limit": limit
        }
        
        if start_time:
            params["startTime"] = int(start_time)
        if end_time:
            params["endTime"] = int(end_time)
        
        try:
            response = requests.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            if not data:
                return pd.DataFrame()
            
            # è§£ææ•°æ®
            df = pd.DataFrame(data, columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_volume', 'trades', 'taker_buy_base',
                'taker_buy_quote', 'ignore'
            ])
            
            # æ•°æ®ç±»å‹è½¬æ¢
            df['timestamp'] = pd.to_datetime(df['open_time'], unit='ms')
            for col in ['open', 'high', 'low', 'close', 'volume', 'quote_volume']:
                df[col] = df[col].astype(float)
            
            # æ·»åŠ amountåˆ—ï¼ˆæˆäº¤é¢ï¼‰
            df['amount'] = df['quote_volume']
            
            # åªä¿ç•™éœ€è¦çš„åˆ—ï¼ŒåŒ…å«amount
            df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume', 'amount']]
            
            return df
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return pd.DataFrame()
        except Exception as e:
            print(f"âŒ æ•°æ®è§£æå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def fetch_historical_data(self, days=90, save=True):
        """
        è·å–å†å²æ•°æ®ï¼ˆæ”¯æŒè¶…è¿‡1000æ¡ï¼Œè‡ªåŠ¨åˆ†æ‰¹ï¼‰
        :param days: è·å–æœ€è¿‘Nå¤©çš„æ•°æ®
        :param save: æ˜¯å¦è‡ªåŠ¨ä¿å­˜
        :return: DataFrame
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹è·å– {self.symbol} å†å²æ•°æ®")
        print(f"{'='*60}")
        print(f"äº¤æ˜“å¯¹: {self.symbol}")
        print(f"æ—¶é—´æ¡†æ¶: {self.interval}")
        print(f"æ•°æ®å¤©æ•°: {days} å¤©")
        
        end_time = int(datetime.now().timestamp() * 1000)
        start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        
        all_data = []
        current_start = start_time
        batch_count = 0
        
        print(f"\nå¼€å§‹åˆ†æ‰¹è·å–æ•°æ®...")
        
        while current_start < end_time:
            batch_count += 1
            print(f"\ræ­£åœ¨è·å–ç¬¬ {batch_count} æ‰¹æ•°æ®...", end="", flush=True)
            
            df = self.fetch_klines(
                start_time=current_start,
                end_time=end_time,
                limit=1000
            )
            
            if df.empty:
                print(f"\nâš ï¸  ç¬¬ {batch_count} æ‰¹æ•°æ®ä¸ºç©ºï¼Œåœæ­¢è·å–")
                break
            
            all_data.append(df)
            
            # æ›´æ–°ä¸‹æ¬¡å¼€å§‹æ—¶é—´ï¼ˆæœ€åä¸€æ¡æ•°æ®çš„æ—¶é—´ + 1æ¯«ç§’ï¼‰
            last_timestamp = df['timestamp'].iloc[-1]
            current_start = int(last_timestamp.timestamp() * 1000) + 1
            
            # é¿å…APIé™æµ
            time.sleep(0.5)
            
            # å¦‚æœè·å–çš„æ•°æ®å°‘äº1000æ¡ï¼Œè¯´æ˜å·²ç»åˆ°æœ€æ–°äº†
            if len(df) < 1000:
                break
        
        print(f"\n\nâœ“ å…±è·å– {batch_count} æ‰¹æ•°æ®")
        
        if not all_data:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return None
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        result_df = pd.concat(all_data, ignore_index=True)
        
        # å»é‡å’Œæ’åº
        result_df = result_df.drop_duplicates(subset=['timestamp'])
        result_df = result_df.sort_values('timestamp').reset_index(drop=True)
        
        print(f"âœ“ æ•°æ®åˆå¹¶å®Œæˆ: {len(result_df)} æ¡è®°å½•")
        print(f"âœ“ æ—¶é—´èŒƒå›´: {result_df['timestamp'].min()} ~ {result_df['timestamp'].max()}")
        
        # ä¿å­˜æ•°æ®
        if save:
            self.save_data(result_df)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        self.display_statistics(result_df)
        
        return result_df
    
    def save_data(self, df):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        # åˆ›å»ºæ•°æ®ç›®å½•
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.symbol}_{self.interval}_{timestamp}"
        
        # ä¿å­˜ä¸ºCSV
        csv_path = self.data_dir / f"{filename}.csv"
        df.to_csv(csv_path, index=False)
        print(f"\nâœ“ CSVå·²ä¿å­˜: {csv_path}")
        
        # ä¿å­˜ä¸ºJSONï¼ˆå¯é€‰ï¼‰
        json_path = self.data_dir / f"{filename}.json"
        df.to_json(json_path, orient='records', date_format='iso')
        print(f"âœ“ JSONå·²ä¿å­˜: {json_path}")
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = self.generate_statistics(df)
        stats_path = self.data_dir / f"{filename}_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        print(f"âœ“ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_path}")
    
    def generate_statistics(self, df):
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        return {
            "symbol": self.symbol,
            "interval": self.interval,
            "total_records": len(df),
            "start_time": str(df['timestamp'].min()),
            "end_time": str(df['timestamp'].max()),
            "duration_days": (df['timestamp'].max() - df['timestamp'].min()).days,
            "price_stats": {
                "min": float(df['low'].min()),
                "max": float(df['high'].max()),
                "avg": float(df['close'].mean()),
                "first": float(df['open'].iloc[0]),
                "last": float(df['close'].iloc[-1]),
                "change": float(df['close'].iloc[-1] - df['open'].iloc[0]),
                "change_percent": float((df['close'].iloc[-1] - df['open'].iloc[0]) / df['open'].iloc[0] * 100)
            },
            "volume_stats": {
                "total": float(df['volume'].sum()),
                "avg": float(df['volume'].mean()),
                "min": float(df['volume'].min()),
                "max": float(df['volume'].max())
            }
        }
    
    def display_statistics(self, df):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        stats = self.generate_statistics(df)
        
        print(f"\n{'='*60}")
        print("ğŸ“Š æ•°æ®ç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"äº¤æ˜“å¯¹: {stats['symbol']}")
        print(f"æ—¶é—´æ¡†æ¶: {stats['interval']}")
        print(f"æ€»è®°å½•æ•°: {stats['total_records']:,} æ¡")
        print(f"æ—¶é—´è·¨åº¦: {stats['duration_days']} å¤©")
        print(f"\nğŸ’° ä»·æ ¼ç»Ÿè®¡:")
        print(f"  æœ€ä½ä»·: ${stats['price_stats']['min']:,.2f}")
        print(f"  æœ€é«˜ä»·: ${stats['price_stats']['max']:,.2f}")
        print(f"  å¹³å‡ä»·: ${stats['price_stats']['avg']:,.2f}")
        print(f"  èµ·å§‹ä»·: ${stats['price_stats']['first']:,.2f}")
        print(f"  æœ€æ–°ä»·: ${stats['price_stats']['last']:,.2f}")
        print(f"  æ¶¨è·Œå¹…: {stats['price_stats']['change_percent']:+.2f}%")
        print(f"\nğŸ“ˆ æˆäº¤é‡ç»Ÿè®¡:")
        print(f"  æ€»æˆäº¤é‡: {stats['volume_stats']['total']:,.2f} BTC")
        print(f"  å¹³å‡æˆäº¤é‡: {stats['volume_stats']['avg']:,.2f} BTC")
        print(f"  æœ€å¤§æˆäº¤é‡: {stats['volume_stats']['max']:,.2f} BTC")
        print(f"{'='*60}")


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("å¸å®‰BTCå†å²æ•°æ®çˆ¬å–å·¥å…·")
    print("="*60)
    
    # ========== é…ç½®å‚æ•° ==========
    symbol = "BTCUSDT"      # äº¤æ˜“å¯¹
    interval = "1h"         # æ—¶é—´æ¡†æ¶ (1m, 5m, 15m, 1h, 4h, 1d)
    days = 730               # è·å–æœ€è¿‘90å¤©æ•°æ®
    # ==============================
    
    # åˆ›å»ºçˆ¬å–å™¨
    fetcher = BinanceHistoricalFetcher(symbol=symbol, interval=interval)
    
    # è·å–æ•°æ®
    df = fetcher.fetch_historical_data(days=days, save=True)
    
    if df is not None and not df.empty:
        print("\nğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå‰10è¡Œï¼‰:")
        print(df.head(10).to_string(index=False))
        
        print("\nğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå10è¡Œï¼‰:")
        print(df.tail(10).to_string(index=False))
        
        print("\nâœ… å†å²æ•°æ®è·å–å®Œæˆï¼")
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {fetcher.data_dir}")
    else:
        print("\nâŒ æ•°æ®è·å–å¤±è´¥")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
